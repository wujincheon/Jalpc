---
layout: post
title: "Paper Review - An End-to-End Trainable Neural Network for Image-based Sequence"
date: 2018-11-28 
desc: "An End-to-End Trainable Neural Network for Image-based Sequence"
keywords: "Image Recognition, CNN, RNN"
categories: [Deep learning]
tags: [Image Recognition, CNN, RNN]
icon: icon-html
---

이번 포스팅에서는 Image to Text를 다룬 연구 중에서 Neural Network를 활용하여 이미지 기반의 시퀀스를 학습하는 논문인 'An End-to-End Trainable Neural Network for Image-based Sequence' - Baoguang Shi. et al,2015 에 대한 리뷰를 해보겠습니다. 



## 1. Introduction - Purpose of the paper
>  
이 논문의 목적은 이미지의 시퀀스를 인식해내는 모델을 제안하는 것으로, 단순히 이미지 인식과는 다르게 어떠한 연속적인 관계를 가지는 이미지를 인식해내는 차이점이 있습니다.  

![](https://i.imgur.com/kWto1AV.png)  
 위 그림과 같이 'STATE' 라는 글자 자체를 인식하는 것이 아니라, 왼쪽부터 순차적으로 이미지를 인식하면서 기존에 존재하는 단어와의 관계를 계산해내면, 좀 더 정확한 인식을 해낼 수 있게 되는 것입니다.  
 지금도 마찬가지이지만 15년도 당시에는 Neural Network가 엄청나게 이슈가 되면서, classification이나 detection과 관련된 분야에 대한 연구가 엄청 활발했습니다. 그 중에서도 본 논문은, 시퀀스가 있는 이미지, 즉 위의 사진과 같이 순서가 있는 형태의 이미지나 음표들이 순차적으로 존재하는 악보 등에 대한 인식을 하는 모델을 제안합니다. 본 모델의 요약입니다.
- end-to-end의 학습이 가능하다.  
- 임의의 길이의 이미지에 대해서 처리가 가능하다.  
- 이미 학습된 어휘뿐 아니라 새로운 단어들에 대해서도 좋은 성능을 보인다.  
- 복잡하지 않은 모델로 실용적이다.



 
##### 이에 대한 과거의 시도들..  
 - DCNN(Deep Convolutional Neural Networks)을 이용해서 이미지에 존재하는 문자들을 따로 따로 인식한 다음 하나로 합쳐서 결과물을 내는 연구가 있었습니다. 근데 이 연구에서는 개별 문자들을 따로 분리해낼 수 있는 아주 강력한 분리 모델이 필요했고 항상 좋은 성능을 가져다줄 수는 없는 상황이었습니다.   
 
 - 또다른 연구에서는 사전에 존재하는 모든 단어들에게 라벨을 학습시켜서, 인식을 하는 것이 아닌 분류 모델을 만들어버리려고 했습니다.(현실적으로 모든 단어를 학습시키는 것이 말이 안됨)  
 - RNN은 시퀀스를 다루기 좋은 모델로써 적합했습니다. 그러나 인풋의 이미지를 피쳐의 시퀀스로 변환하는 것이 매우 중요한 작업인데, 이 과정이 RNN의 모델에 사용되기 이전에 따로 분리되어서 진행이 되므로, 본 논문에서 제안하고자 하는 end-to-end의 형태는 띄지 못했습니다.
  
  
  
  
  
##### 본 논문의 장점 및 의의
 - DCNN + RNN 의 CRNN이라는 새로운 네트워크 구조를 가진다는 것
 
 - 문자단위가 아닌 word 단위로 학습한다는 것
 - 시퀀스의 길이에 구애받지 않고 DCNN보다 훨씬 적은 parameter를 가진다는 것 
 
 - preprocessing 및 segmentation 등의 과정이 불필요하다는 장점

 
 
 
## 2. The Proposed Network Architecture 
>  
아래의 그림처럼 본 논문에서 제안하고자 하는 모델은 다음과 같습니다. 
![](https://i.imgur.com/VRkBRoB.png)   
이미지를 넣으면 그의 특징을 파악해내는 피처맵들을 만들고, 그 피처맵들을 일정한 colume별로 concat해서 연속된 형태의 피처 시퀀스를 만들어냅니다. 그리고 그 시퀀스를 RNN 모델에 대입해서 어떤 문자인지에 대한 라벨을 찾아내는 모델입니다.


##### 1. Extract Feature Sequence
- CRNN 모델에서 Convolutional Layer는 기존 CNN 모델의 fully-connected layer가 제거된 부분으로 이루어져 있습니다. 이 층에서는 인풋 이미지에서 sequential한 피처를 뽑아내는 것을 목적으로 합니다. 그리하여 얻은 피처를 시퀀스로해서 recurrent layer의 인풋으로 들어가게 됩니다.

- 각각의 feature vector들은 왼쪽부터 차례대로 블럭화시켜서 만들어냅니다.(convolution, max-pooling, activation function 등을 통해) : 이 부분이 기존에는 전체의 이미지를 나타내는 representation을 찾으려고 했으나, 그러려면 정해진 길이로 전처리를 해야하고 어려움이 많기 때문에 이 모델에서는 구간별로 쪼개서 피처들의 벡터를 시퀀스로 만들어내는 것입니다.

##### 2. Sequence Labeling 
위에서 말한 것처럼, 쪼개진 이미지에 대한 라벨값들을 따로, 순차적으로 예측을 하게 됩니다. 이 모델에서 추구하는 bidirectional LSTM을 사용하게 되어 생기는 이 라벨링 방법의 장점에는 3가지가 있습니다.

1. 순차적으로 예측하기 때문에, 왼쪽의 이미지에 대한 라벨로부터 영향을 받아서 예측을 하게 됩니다. 그러면 개별적으로 문자들을 독립적으로 인식하는 것보다 훨씬 안정적이고 효율적입니다. 왜냐하면 완벽하게 분리해낼 수 없는, 좀 애매한 형태의 이미지의 경우, 문맥상에서 문자를 파악해낼 수도 있기 때문입니다.(텍스트라는 것이 연속적인 frame을 가지기 때문)

2. 그리고 RNN은 역전파로 학습을 할 수 있기 때문에 Convolutional layer와 같이 학습을 반복할 수 있습니다. 즉, 인식을 해내는 부분뿐만 아니라, 앞단에서 피처 벡터를 만들어내는 것, 피처 시퀀스를 만들어내는 과정도 계속해서 수정하면서 학습해나간다는 것입니다.

3. 또한 쪼개서 순차적으로 인식을 하기 때문에, 이미지 전체의 라벨을 나타내야 하는 모델처럼 시퀀스의 길이를 지정해주지 않아도 됩니다.

- 본 모델에서 LSTM을 활용하는 것은, vanishing radient problem이 있기 때문인데, 양방향으로 학습을 하고 싶어서 LSTM을 양방향으로 배치하여 bidrectional LSTM을 만들어 냈습니다.


##### 3. Transcription
- per-frame prediction 즉, 위에서 나눈 이미지의 부분부분을 예측한 라벨값들을 라벨의 시퀀스로 합치는 과정입니다. 이렇게 합치면서 수학적으로, 확률적으로 높은 확률의 라벨을 찾는 과정입니다.

**Probability of label sequence** : 시퀀스의 길이가 T라고 할때, 그 T개만큼의 라벨이 주어졌을때, 공백으로 인식되는 부분을 지우고 존재하는 단어로의 확률값들을 계산할 수 있습니다. 

**Lexicon-free transcription** : 그러면 여기서 단어를 기반으로 하지 않은 상태에서, 가장 확률값을 크게하는 단어를 찾아놓을 수 있습니다.

**Lexicon-based transcription** : 그러면 다시, 어휘 사전을 기반으로 해서, 가장 높은 확률을 가질 시퀀스 라벨을 찾아내는 것입니다. 굳이 두 단계를 거치는 이유는, 모든 시퀀스 라벨에 대해서 확률값을 계산하고 선택하는 시간 비용이 크기 때문에, Lexicon-free 방식으로 추정을 어느정도 한 다음 거리기반으로 가까운 확률의 라벨을 선택하는 것입니다.

##### 4. Network Training
- 이제껏 설명했던 시퀀스에 대한 라벨 확률값을 목적함수로 해서 end-to-end로 학습을 시킵니다.

## 3. Experiments


![](https://i.imgur.com/3C6BCwt.png)  
본 논문에서는 IC13, IIIT5k, SVT dataset을 이용해서 실험을 진행했습니다.
 
![](https://i.imgur.com/xBKMZHK.png)  
그 결과 위와 같이 본 논문에서 제시하는 CRNN 구조의 모델이 가장 좋은 성능을 보인다고 말하고 있습니다.







## 4. Conclusions

- ##### 이전에 없던 새로운 뉴럴 네트워크의 구조를 제안
- ##### 정해지지 않은 임의의 길이의 시퀀스에 대한 처리가 가능한 모델
- ##### 텍스트에서 매우 우월한 성능을 보이며, 다른 도메인에도 적용이 가능
- ##### 기존의 fully-connected layer를 버림으로써 compact하고 효율적인 모델 제안


## 마치며..

단순히 이미지로부터 어떠한 물체를 인식하는 것에 대한 연구는 많이 보았습니다. 그러나 이미지를 하나의 시퀀스로 보고 순차적으로 학습해낸다는 것에 대해서는 처음으로 접한 논문이었습니다. 비록 많은 논문을 아직 접해보지는 못했지만, 점점 더 사물인식에 대한 연구가 활발해지고 고도화되고 있는 가운데 이에 대한 기초적인 지식이나 기술은 갖춰야한다고 느꼈습니다. 그래서 Object Detection이라는 분야에 대해서 이전 논문부터 차근차근 읽어보고 정리하고 있으며, 이는 추후에 포스팅하도록 하겠습니다.
