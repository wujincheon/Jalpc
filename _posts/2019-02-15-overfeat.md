---
layout: post
title: "Paper Review - Object Detection 2 (OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks)"
date: 2019-02-15
desc: "Paper Review - Object Detection 2 (OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks)"
keywords: "CNN, Overfeat, Object Detection, Localization, Recognition"
categories: [Deep learning]
tags: [CNN, Overfeat, Object Detection, Localization, Recognition]
icon: icon-html
---

이번 포스팅에서는 Object Detection의 두 번째로, Overfeat이라고 불리우는 모델에 대해 알아보겠습니다. Overfeat은 R-CNN과 비슷한 시기에 발표된 논문이지만 의의가 다릅니다. R-CNN과는 다르게 이미지에 대한 convolution network을 한번만 거치도록 설계되었습니다. 그리고 뒷단에서 다양하게 위치를 탐색하는 구조인데요, 자세히 살펴보겠습니다.  

---


## 1. Introduction  

##### 1. ImageNet의 데이터에 있는 1000여개의 카테고리에 대해 object를 분류해내는 CNN 구조 적용 선행연구

##### 2. ConvNets을 사용하면 픽셀에서 카테고리까지 end to end로 학습시킬 수 있음

##### 3. Object가 이미지에 따라 크기가 달라지므로, 다양한 위치에서 object를 찾으려는 시도들이 있었음(sliding window, multi-scales) 

##### 4. viewing window에 따라 object를 다르게 판별하므로, 정확한 window 필요함
- 앞선 포스팅에서도 이야기했지만, WINDOW SLIDING을 하는 것은 정확한 박스를 만들어내기 어렵다는 것입니다. 그래서 이를 통한 성능 향상이 중요하다고 하고 있습니다.  

##### 5. 그래서 bounding box를 움직여가며 학습 + bounding box의 위치와 크기를 예측할 것임


---

## 2. Related Work  
![](https://i.imgur.com/pN6k5Xy.png?1)  
본 논문은 Recognition, Localization, Detection을 동시에 학습하는 연구로, 여러 task를 동시에 학습한 유사한 연구가 있었다고 합니다. 위에 그림이 그 내용인데, 얼굴과 얼굴이 아닌 부분이 같은 이미지에 있다고 해봅시다. 그러면 학습과정에서 이를 특정 저차원의 공간에 매핑하는 함수를 학습시키게 됩니다. 그렇게 해서 만들어진 공간에서는 face 매니폴드를 만들어내게 됩니다. face 매니폴드에 속하면 얼굴로 분류하는 것이고, 다른 공간에 속하면 얼굴이 아닌 무언가로 분류하게 됩니다. 여기서 매니폴드 상에 어떤 위치에 존재하느냐에 따라 얼굴의 pose까지 결정할 수 있기 때문에 동시에 두 task를 한다고 볼 수 있습니다.


---

## 3. Purpose of the paper
##### 1. Object의 경계선 예측을 학습하는 새로운 딥러닝 접근법 제안 (localization prediction 들을 합쳐서 background sample에 대한 학습없이도 성능 향상되도록 고안)  

##### 2. CNN을 기반으로 하여 classification, localization, detection을 하는 통합된 end-to-end의 framework을 제안

##### 3. 개별 task를 학습하는 것보다 세 task를 동시에 학습하는 것의 성능이 향상됨을 보임 

---

## 4. Overfeat

##### Classification - Architecture  
![](https://i.imgur.com/ekovJwe.png?1)  
이 구조는 Imagenet classification with DCNN 이라는 논문에서 차용한 구조로써, 조금의 수정을 거쳐서 task에 사용했습니다. Fast와 Accurate 두 버전을 제안하고 있는데, conv 과정에서 stride를 다르게 적용함으로써 원래의 이미지에 대한 정보를 좀 더 저장해서 성능을 높이느냐, 빠르게 처리하느냐 하는 다른 목적을 가지고 있습니다. 그 외에도 배치사이즈를 변경하고 Pooling region을 겹치지 않게 설정하는 등 조금의 수정이 있었다고 합니다.  
##### Classification - dense evaluation
각 이미지를 256x256 크기로 만들고, 아래의 그림처럼 221x221 크기로 추출한 5개 random crop과 좌우 반전으로 총 10개를 이용해서 training 진행합니다.  
![](https://i.imgur.com/3TjAcdm.png?1)  
그런데 Testing 단계에서도 이러한 multi-view voting을 하면 영상의 많은 부분이 무시될 수 있고, 컴퓨팅 연산량이 많아지기 때문에 이미지 전체에 대해 ConvNet을 적용하려 했으나 인풋 사이즈를 정해주는 바람에 이또한 성능을 저하시켰습니다. 그래서 본 논문에서 고안하는 것이 'Multi-scale dense evaluation' 입니다.  

![](https://i.imgur.com/yPQAwcl.png?1)  
이를 본 논문에서 설명하는 Scale 2에 대해서 설명해보도록 하겠습니다.  

![](https://i.imgur.com/9zmvT20.png?1)  
20 x 23 에서 우선 3x3의 영역이 겹치지 않도록 쭉 메워주면 파란색부분처럼 18x21 만큼이 차지하게 됩니다. 그래서 세로는 6개, 가로는 7개이기 때문에 6x7가 만들어지는 것입니다. 그리고 각각의 3x3에 대해서 0,1,2 씩 sliding하면서 오른쪽의 5x5를 채우게 됩니다. 이 5x5는 다른 3x3이 지정되는 영역과 하나도 겹치지 않다는 것을 보여주기 위해 그린 것입니다. 그러면 다른 윈도우와 겹치지 않는 선에서 가로로 3개 , 세로로 3개가 만들어지기 때문에 6x7에 3x3이 곱해지는 것입니다.  

![](https://i.imgur.com/BgY6fiP.png)  
그런 다음은, 5x5의 고정된 길이의 인풋을 가지는 classifier에 넣기 위해서 5x5의 형태로 sliding을 합니다. 6x7에 대해 5x5로 1씩 움직이면서 매핑을 하면 오른쪽과 같이 2x3의 맵이 만들어지게 됩니다. 그리고 C는 여기서 class별로 따로 계산을 한다는 의미입니다. 기존의 풀링과는 다르게 연산 시간은 더 걸리지만, 피처맵의 모든 지역에 대해 좀 더 세밀하게 정보를 담는다고 생각할 수 있습니다. 그렇게 해서 성능 향상에 이바지 할 수 있는 것입니다.

##### Classification - Results
![](https://i.imgur.com/nD3YZjU.png?1)  
위의 테이블이 Validation dataset에 다양한 조건을 주어가며 실험을 진행한 것입니다.  
Coarse는 sliding을 하지 않은 것, Fine은 sliding을 앞서 말한 것처럼 0,1,2로 주어가며 dense evaluation 진행한 것입니다.  
테이블에서 알 수 있듯이 Single scale보단 multi scale이, coarse stride보단 fine stride가, fast보단 accurate가 좋음을 보여주고 있습니다. 즉, 본 논문에서 제시하는 dense evaluation의 성능 향상 역할을 알 수 있습니다.  

##### Localization - Generating predictions & Regressor training  
Classification 을 학습한 모델에서 classifier layer 를 regression network 로 변경합니다. 그리고 layer 5에서 얻은 피처맵들을 이용해서 아래의 그림에서 제시하는 대로 네트워크를 거치게 됩니다. d에 보면 마지막에 채널 값들을 얻게 되는데 이것이 위치 정보를 의미하게 됩니다. 그래서 그 정보와 실제 bounding box의 위치를 target으로 하여 학습하게 됩니다.  

![](https://i.imgur.com/z3r2bHL.png)  

##### Localization - Combining Predictions
아래의 그림처럼 여러개의 박스를 합치고 합쳐서 하나의 박스를 만드는 과정은 다음과 같습니다.  
1. 먼저 이미지에 해당하는 클래스를 할당한다.
2. 그리고 박스별로 그 클래스에 대한 confidence score를 구한다.
3. 겹치는 부분과 거리를 고려한 match_score값을 기준으로 가장 근접한 박스 두 개를 선정한다.
4. 두 박스를 합쳤을 때 클래스에 대한 confidence가 상승하면 합친다.

![](https://i.imgur.com/hQzfvOK.png?1)  

##### Detection
detection에서는 앞단에서 계산된 모든 weight들을 공유합니다. 앞의 task와의 큰 차이점이라고 한다면, 이 task에서는 아무 object도 없는 이미지가 있기 때문에 이에 대해 negative example을 만들어서 학습시킨다는 점입니다. 그 결과를 적용했을때 아래 표와 같이 우월한 성능을 보임을 나타내고 있습니다.  
![](https://i.imgur.com/ac4BXJS.png?1)

---

## 5. Conclusions
- 2013 ILSVRC 대회 localization 부문 1위, classification 4위, detection 1위로 세 분야를 모두 출전해서 우수한 성적을 보인 모델은 유일  

- Multi-scale 개념과 sliding window 접근법을 세 task를 학습하는 ConvNet에 효과적으로 적용함

- 연산이 복잡하지 않기에 연산량 관점에서는 R-CNN에 비해 효과적이면서 성능도 비교할만한 정도

- 고정된 크기의 이미지가 인풋으로 들어가야 한다는 단점과 다양한 scale의 여러 object를 탐색하는 데에 한계



---

## 다음 포스팅에는..

Object Detection-3, R-CNN과 Overfeat의 연산량이나 성능부분에서 겪었던 한계점을 조금씩 개선되었다고 볼 수 있는 SPPNet에 대해서 살펴보겠습니다. Overfeat은 R-CNN이 가지고 있는 계산량의 문제점을 최대한 해결하고자 했다는 점에서 의의가 있습니다.
