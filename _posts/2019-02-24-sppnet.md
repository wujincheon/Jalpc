---
layout: post
title: "Paper Review - Object Detection 3 (Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition)"
date: 2019-02-24
desc: "Paper Review - Object Detection 3 (Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition)"
keywords: "CNN, SPPNet, Object Detection, Localization, Recognition"
categories: [Deep learning]
tags: [CNN, SPPNet, Object Detection, Localization, Recognition]
icon: icon-html
---

이번 포스팅에서는 Object Detection의 세 번째로, SPPNet이라고 불리우는 모델에 대해 알아보겠습니다. SPPNet은 R-CNN의 계산량에 대한 문제, 그리고 Overfeat의 다양한 스케일 탐색 한계에 대한 문제, 그리고 성능을 좀 더 향상시키고자 고안된 모델입니다.   

---


## 1. Introduction  

과거에 사용된 CNN 구조들에서는 fully-connected layer에 고정된 길이의 입력이 필요하기 때문에 이미지가 왜곡될 가능성이 있었습니다. 그러나 본 논문에서 제시하는 것은 conv 층을 먼저 거친 다음 layer 5에서 나온 피처맵들을 대상으로 SPP layer를 거치는 것입니다. 차별점이 여기서 나오는데, SPP layer를 거쳐서 임의의 크기의 이미지에 대해서 항상 같은 길이의 벡터를 만들어낸다는 것입니다. 그렇게 되면 crop을 하거나 warp을 해서 이미지를 왜곡시키지 않아도 본 이미지에 대해서 항상 처리가 가능하게 되기 때문입니다.  
![](https://i.imgur.com/nEc5edB.png?1)  



---

## 2. SPPNet : an extension of Bag-of-Words model  
![](https://i.imgur.com/PYAe83h.png?1)  
SPPNet을 BoW 모델의 확장판이라고 불리기도 하는데, 그 이유는 SPPNet도 BoW 처럼 이미지를 구성하는 특징들로 이미지를 나타내는 개념이기 때문입니다. 이미지들에서 나타나는 피처들을 먼저 구성해놓고 피처들을 이용해서 본 이미지를 표현하는데, 이는 고정된 크기의 필터들로 피처맵의 특징을 뽑아내는 SPPNet의 메커니즘과 유사하다고 할 수 있습니다. 자세한 내용을 뒤에서 보면 이해가 될 것입니다.  



---


## 3. SPPNet : Contribution
![](https://i.imgur.com/Hm2UsRw.png?1)  

##### 1. 고정된 인풋 크기가 아닌 임의의 크기 이미지에 대해 CNN으로 학습을 하고 conv5 layer까지 동일  

##### 2. R-CNN과 다르게 전체 이미지에 대해 한 번만 수행하므로 수 백배 빠름
- R-CNN은 Selective Search로 만들어낸 후보 지역 2천여개에 대해서 모두 CNN을 수행했었음

##### 3. 다양한 크기의 bin을 통해 고정된 길이의 결과값을 만듦과 동시에, 다양한 scale의 특징을 추출
- 뒤에서 자세히 설명하겠지만 다양한 크기의 bin과 조합을 이용하므로, 다양한 스케일의 object를 찾는 학습을 할때 특정 스케일에 overfitting되는 것을 감소시킬 수 있다고 함

##### 4. Classification과 detection 모두에서 강점을 보임

##### 5. ECCV 2014 초기 버전 발행 후, ILSVRC 2014에 출전하여 좋은 성적을 보이면서 피처맵에 대한 multi-view test가 classification task에 좋은 성능을 가져옴을 알게 됨.

---

## 4. SPPNet

##### Spatial Pyramid Pooling layer
![](https://i.imgur.com/3nipkb7.png?1)  
왼쪽 그림에서처럼 미리 윈도우에 대해 추출할 특징의 개수, 4x4, 2x2, 1x1 이렇게 총 세 종류로 21개의 bin을 미리 설정해야 합니다. conv layer 5에서 얻어진 피처맵에 대해서 윈도우로 탐색을 할텐데, 각 윈도우마다 다양한 스케일의 특징을 뽑아내기 위해서 bin의 사이즈를 조정해놓는 것입니다. 그렇게 미리 bin의 모양과 개수를 정해놓으면 이미지의 크기가 어떻게 들어오든간에 항상 같은 개수의 특징을 뽑아내기 때문에 항상 고정된 길이의 벡터를 만들어내는 것입니다.  
bin의 개수는 늘려갈수록 더 많은 특징과 scale에 대해 정보를 얻을 수 있기 때문에 robust한 형태를 띄지만 매우 계산이 복잡해진다는 단점이 있기 때문에 적절히 조정하는 것이 중요합니다.  

그럼, 13x13의 형태에서 3x3 인 9개의 bin으로 9개의 특징을 뽑아내고자 하면 어떻게 하면 될까?  
아래 그림처럼, 5x5의 크기로 stride 4를 적용하여 sliding하면서 추출하면 인풋이 어떤 사이즈가 되던간에 원하는 개수만큼의 특징을 추출할 수 있습니다. stride나 윈도우의 크기는 구하는 공식이 논문에 있기 때문에 참조하시면 됩니다.
![](https://i.imgur.com/YYqQeaR.png)

---

## 5. SPPNet : Classification
##### Dataset
![](https://i.imgur.com/PQcFZHf.png?1)  

- ImageNet 2012 의 1000-category train set으로 학습

- 분류할 이미지를 256x256의 사이즈로 크기 조절

- 조절한 이미지에 대해 224x224의 사이즈로 crop(코너4개와 센터 및 좌우대칭)하여 augmentation을 진행

- SPPnet을 거친 피처벡터에 softmax 스코어를 계산하여 분류에 사용

##### Baseline
![](https://i.imgur.com/5EDkXUs.png)  
SPPNet의 장점은 Conv 네트워크 구조에 독립적이라는 것입니다. 그래서 기존에 있던 4개의 네크워크 구조(ZF-5, Convnet, Overfeat)에 대해서 SPPNet을 적용하여 개선됨을 실험하고자 했습니다.

##### Baseline + SPP layer
![](https://i.imgur.com/4uCb0Oa.png)  
이 테이블에 진행된 실험에서는 총 4-level pyramid를 사용해서 50개의 bin을 사용했습니다.
SPP를 사용하지 않은 것보다 다중 수준의 풀링을 진행하면 parameter를 더 사용하면서 object 변형이나 공간에 대해서 robust하기 때문에 에러율이 향상되는 것을 보여주고 있습니다. 또한 multi-size 학습을 하게 되면, no SPP나 single-size보다 향상됨을 알 수 있습니다.

##### Representational power of Full image
![](https://i.imgur.com/HN7DMMZ.png)  
전체 이미지에 대해 적용한 것이 full이고, 위에서 언급한 224의 사이즈로 crop한 것이 crop입니다. 대부분의 실험에서 알 수 있듯이, 전체 이미지를 사용하면 crop한 것보다 결과가 좋음을 알 수 있습니다. 여기에서 완전한 content를 유지하는 것이 중요하다는 것을 보여주고 있습니다.

##### Experiments
![](https://i.imgur.com/u2bd5Qo.png)  
맨 아래의 경우 6개의 스케일에 대해, 각 스케일마다 18개의 뷰를 사용하는데 원본이 224인 경우에는 6개의 뷰만 존재하므로 총 96개의 뷰를 test view로 사용해서 96+ 2full 임을 알 수 있습니다.  
결과를 보면 ImageNet 2012에서 최고 수준이었던 모델들보다 에러율을 매우 향상시킬 수 있었고 ILSVRC 2014에서도 3위에 해당하는 좋은 결과를 얻음을 보여주고 있습니다.

##### Experiments on VOC 2007
![](https://i.imgur.com/rFW1wy7.png)  
20 category가 존재하는 9963개의 이미지에 대해 task를 실험, ImageNet으로 pre-training된 네트워크를 이용하여 SVM classifiers를 다시 학습해서 분류에 사용했다고 합니다.  
그런데 여기서 C보다 D에서 즉, 392사이즈를 쓴 것이 좋아진 이유는 기존의 ImageNet에서의 이미지보다 상대적으로 작은 스케일을 가지는 데이터이기 때문이라고 합니다. 


##### Experiments on Caltech 101
![](https://i.imgur.com/4uCb0Oa.png)  
102 category가 존재하는 9144개의 이미지에 대해 task 실험, 카테고리당 이미지를 랜덤으로 30~50개씩 10회 반복해서 뽑아서 진행했다고 합니다.
여기선 위의 실험과 달리 224로 유지시킨걸 알 수 있는데, object가 차지하는 region이 비슷하기 때문입니다. 계속해서 알 수 있듯이, spp를 사용한 모델이 더 좋은 결과를 보이고 있습니다.

---

## 6. SPPNet : Detection
1. Detection 에 대한 적용에서는 Selective Search의 fast 모드를 사용해서 이미지당 2천여개의 후보 윈도우를 생성합니다. 
2. 전체 이미지에 대해 피처맵을 뽑고, 4-level의 spp layer를 적용시킵니다. (총 50개의 bin * 256개의 필터) 
3. 2천여개의 윈도우마다 1280이라는 고정된 길이의 피처벡터를 추출해내서 svm classifier에 학습합니다.
4. positive, negative sample를 생성해서 이진분류의 개념으로 학습합니다. (negative sample은 positive 윈도우와 IoU값 기준으로 0.3 이하인 부분)
5. 여러 스케일들에서 따로 피처맵들을 계산하고, 224에 가장 가까운 값을 가지는 스케일을 선택하여 그 피처맵을 이용했다고 합니다...

![](https://i.imgur.com/h0azzUv.png)  
Pascal VOC 2007에 대한 mAP 결과값으로, scale을 변화시키며 SPP를 적용한 것과, RCNN의 결과를 비교했는데,
Ft(fine tuning)과 bb(bounding box regression)을 이용하면서 더 좋은 성능을 보임을 알 수 있습니다.  
그리고 R-CNN보다 좋은 성능을 보이는 SPP layer 적용 실험으로써 성능 향상에 대한 실험을 보여주고 있습니다.

---

## 7. Conclusions
- ILSVRC2014 detection 2위, classification 3위  

- R-CNN과 정확도는 비슷하나 속도가 20 ~ 100배 빠름

- 임의의 크기의 이미지에 대해 항상 고정된 크기의 출력을 만들어줌

- 다양한 수준의 pooling을 통해 좀 더 많은 정보들을 담는 결과값을 얻어냄



---

## 다음 포스팅에는..

Object Detection과 관련해서 Feature Pyramid Networks라고 다양한 스케일의 물체를 찾아내기 위해 도움을 주는 네트워크에 대한 논문을 살펴보겠습니다.
